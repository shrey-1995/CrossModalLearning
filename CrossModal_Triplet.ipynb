{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "gy7yRBcHpN1K",
    "outputId": "8dd7cc8c-0a58-4640-844e-c0c5d03371b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks/Cross Modal Retrieval\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd '/content/drive/My Drive/Colab Notebooks/Cross Modal Retrieval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Rsw56mf3JfK0",
    "outputId": "e3e95053-6096-496f-c504-7e9e99504343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open3d\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f9/c4ae8750e8c90d3d45da45ff08f87040ec70dc596a1c94a3bef01faff6ce/open3d-0.10.0.0-cp36-cp36m-manylinux1_x86_64.whl (4.6MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6MB 74kB/s \n",
      "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from open3d) (7.5.1)\n",
      "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.6/dist-packages (from open3d) (3.5.1)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from open3d) (5.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from open3d) (3.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from open3d) (1.18.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->open3d) (4.3.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->open3d) (5.0.7)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->open3d) (5.5.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->open3d) (4.10.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->open3d) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->open3d) (4.6.3)\n",
      "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->open3d) (0.8.3)\n",
      "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->open3d) (4.5.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->open3d) (2.11.2)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->open3d) (5.6.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->open3d) (5.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->open3d) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->open3d) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->open3d) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->open3d) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets->open3d) (1.12.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets->open3d) (4.4.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->open3d) (2.6.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (2.1.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (47.3.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (1.0.18)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (0.7.5)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (0.8.1)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->open3d) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->open3d) (1.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->open3d) (0.8.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->open3d) (0.4.4)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->open3d) (3.1.5)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->open3d) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->open3d) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->open3d) (0.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->open3d) (19.0.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->open3d) (0.2.4)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->open3d) (0.5.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->open3d) (20.4)\n",
      "Installing collected packages: open3d\n",
      "Successfully installed open3d-0.10.0.0\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
      "Collecting torch-geometric\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/f2/26359fb7b50d54924ddd23778d4830b2653df9ffe72f85caad2b829dc778/torch_geometric-1.5.0.tar.gz (153kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 2.8MB/s \n",
      "\u001b[?25hCollecting torch-sparse==latest+cu101\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.6MB)\n",
      "\u001b[K     |████████████████████████████████| 21.6MB 1.3MB/s \n",
      "\u001b[?25hCollecting torch-scatter==latest+cu101\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.2MB)\n",
      "\u001b[K     |████████████████████████████████| 12.3MB 68.0MB/s \n",
      "\u001b[?25hCollecting torch-cluster==latest+cu101\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (18.2MB)\n",
      "\u001b[K     |████████████████████████████████| 18.2MB 147kB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.5.0+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
      "Collecting plyfile\n",
      "  Downloading https://files.pythonhosted.org/packages/93/c8/cf47848cd4d661850e4a8e7f0fc4f7298515e06d0da7255ed08e5312d4aa/plyfile-0.7.2-py3-none-any.whl\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.0.4)\n",
      "Collecting rdflib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 8.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
      "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
      "Collecting ase\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/70/a8b1a7831193aa228defd805891c534d3e4717c8988147522e673458ddce/ase-3.19.1-py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 12.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.15.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (47.3.1)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.4.5.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
      "Collecting isodate\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.12.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (1.2.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-geometric: filename=torch_geometric-1.5.0-cp36-none-any.whl size=267918 sha256=66799aecc851346817875b42111174b930c5bd4adf1bda535ba9b34c38673655\n",
      "  Stored in directory: /root/.cache/pip/wheels/ec/51/31/5786f2ac419ee312f22d4d2877da05f20e7f2d430e22917daf\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: plyfile, isodate, rdflib, ase, torch-geometric, torch-sparse, torch-scatter, torch-cluster\n",
      "Successfully installed ase-3.19.1 isodate-0.6.0 plyfile-0.7.2 rdflib-5.0.0 torch-cluster-1.5.4 torch-geometric-1.5.0 torch-scatter-2.0.4 torch-sparse-0.6.5\n"
     ]
    }
   ],
   "source": [
    "!pip install open3d\n",
    "!pip install torch-geometric \\\n",
    "  torch-sparse==latest+cu101 \\\n",
    "  torch-scatter==latest+cu101 \\\n",
    "  torch-cluster==latest+cu101 \\\n",
    "  -f https://pytorch-geometric.com/whl/torch-1.5.0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jp3OdK3ZpN1O",
    "outputId": "5259ea1d-bdb8-4842-a604-9e32c02dfabd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_matrix: (87, 200) sentences: (15, 47) modelIdList: 15\n"
     ]
    }
   ],
   "source": [
    "from text_extraction_torch import get_text_embedding\n",
    "import open3d as o3d\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "embedding_matrix, encoder_input_sentences,modelIdList,categoryList = get_text_embedding(\"descriptions.csv\")\n",
    "print(\"embedding_matrix:\",embedding_matrix.shape,\"sentences:\",encoder_input_sentences.shape,\"modelIdList:\",len(modelIdList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dg0dwhSLpN1T"
   },
   "outputs": [],
   "source": [
    "class ShapeText(Dataset):\n",
    "    def __init__(self, encoder_input_sentences,modelIdList, categoryList, train=True, transform=None):\n",
    "        self.is_train = train\n",
    "        self.transform = transform\n",
    "        self.encoder_input_sentences = encoder_input_sentences\n",
    "        self.files = []\n",
    "        for idx,modelId in enumerate(modelIdList):\n",
    "            sample = os.path.join(categoryList[idx], modelId + \".ply\")\n",
    "            self.files.append(sample)\n",
    "          \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __preproc__(self, pcd_load):\n",
    "        # convert Open3D.o3d.geometry.PointCloud to numpy array\n",
    "        xyz_load = np.asarray(pcd_load.points)\n",
    "        color_load = np.asarray(pcd_load.colors)\n",
    "        if self.transform:\n",
    "            xyz = self.transform(xyz_load)\n",
    "        return xyz,color_load\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]\n",
    "        pcd_load = o3d.io.read_point_cloud(pcd_path)\n",
    "        pos_xyz, pos_color = self.__preproc__(pcd_load)\n",
    "        pos_desc = self.encoder_input_sentences[idx]\n",
    "        if not self.is_train:\n",
    "          return self.files[idx], {'xyz': pos_xyz, 'color': pos_color}, pos_desc\n",
    "        negative_idx = random.choices([ i for i in range(len(self.files)) if (i != idx and modelIdList[i]!=modelIdList[idx])],k=5)\n",
    "        neg_shape = []\n",
    "        neg_text = []\n",
    "        for i in range(len(negative_idx)):\n",
    "          neg_desc = self.encoder_input_sentences[i]\n",
    "          pcd_path = self.files[i]\n",
    "          pcd_load = o3d.io.read_point_cloud(pcd_path)\n",
    "          neg_xyz, neg_color = self.__preproc__(pcd_load)\n",
    "          neg_shape.append({'xyz': neg_xyz, 'color': neg_color})\n",
    "          neg_text.append(neg_desc)\n",
    "        return self.files[idx],{'xyz': pos_xyz, 'color': pos_color},pos_desc, neg_text,neg_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jez5dl4zpN1Z"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin= 0.6):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "       # x1_norm = x1.norm(p=2,dim=1)\n",
    "      #  x2_norm = x2.norm(p=2,dim=1)\n",
    "        return (x1 - x2).pow(2).sum(1)\n",
    "    \n",
    "    def forward(self, positive_shape: torch.Tensor, positive_text: torch.Tensor, negative_text: torch.Tensor, negative_shape: torch.Tensor) -> torch.Tensor:\n",
    "        distance_positive = self.calc_euclidean(positive_shape, positive_text)\n",
    "        distance_negative = self.calc_euclidean(positive_shape, negative_text)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "        distance_positive = self.calc_euclidean(positive_shape, positive_text)\n",
    "        distance_negative = self.calc_euclidean(negative_shape, positive_text)\n",
    "        losses += torch.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XyJmV2kupN1f"
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        \n",
    "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0)\n",
    "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "\n",
    "        return  norm_pointcloud\n",
    "\n",
    "class RandRotation_z(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        theta = random.random() * 2. * math.pi\n",
    "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
    "                               [ math.sin(theta),  math.cos(theta),    0],\n",
    "                               [0,                             0,      1]])\n",
    "        \n",
    "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "        return  rot_pointcloud\n",
    "    \n",
    "class RandomNoise(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
    "    \n",
    "        noisy_pointcloud = pointcloud + noise\n",
    "        return  noisy_pointcloud\n",
    "        \n",
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        return torch.from_numpy(pointcloud)\n",
    "    \n",
    "def default_transforms():\n",
    "    return transforms.Compose([ Normalize(),\n",
    "                                ToTensor()\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RF-5zNbWmVEN"
   },
   "outputs": [],
   "source": [
    "def calculateNearest(firstEmbed,secEmbed):\n",
    "  correctIndex = []\n",
    "  predictedIndex = []\n",
    "  difference = []\n",
    "  firstEmbed_norm = firstEmbed.norm(p=2,dim=1)\n",
    "  secEmbed_norm = secEmbed.norm(p=2,dim=1)\n",
    "  for i in range(len(firstEmbed)):\n",
    "      distance = (secEmbed-firstEmbed[i]).pow(2).sum(1)\n",
    "      idx, val= torch.argmin(distance).item(),torch.min(distance).item()\n",
    "      correctIndex.append(i)\n",
    "      predictedIndex.append(idx)\n",
    "      difference.append(val)\n",
    "  print(\"correctIndex:\", correctIndex)\n",
    "  print(\"predictedIndex:\", predictedIndex)\n",
    "  print(\"difference:\", difference)\n",
    "  return correctIndex,predictedIndex,difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jkgcfa87pN1i"
   },
   "outputs": [],
   "source": [
    "from PointNet2 import Net\n",
    "from embedding import Encoder\n",
    "import random\n",
    "\n",
    "train_split =  int(0.8 * len(modelIdList))\n",
    "val_split = int(0.9 * len(modelIdList))\n",
    "train_ds = ShapeText(encoder_input_sentences[ :train_split,:], modelIdList[ :train_split], categoryList[ :train_split], transform=default_transforms())\n",
    "\n",
    "val_ds = ShapeText(encoder_input_sentences[train_split:val_split,:], modelIdList[train_split:val_split],\n",
    "                     categoryList[train_split:val_split], train = False, transform=default_transforms())\n",
    "test_ds = ShapeText(encoder_input_sentences[val_split: ,:], modelIdList[val_split: ], categoryList[val_split: ],\n",
    "                    train = False, transform=default_transforms())\n",
    "train_loader = DataLoader(dataset=train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_ds, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "HIDDEN_SIZE = 300\n",
    "criterion = TripletLoss()\n",
    "shape_model = Net(300).to(device)\n",
    "text_model = Encoder(embedding_matrix, HIDDEN_SIZE, n_layers=2).to(device)\n",
    "#shape_model.load_state_dict(torch.load(\"shape_model1.checkpoint\"))\n",
    "#text_model.load_state_dict(torch.load(\"text_model1.checkpoint\"))\n",
    "params = list(shape_model.parameters()) + list(text_model.parameters()) \n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "shape_model.train()\n",
    "text_model.train()\n",
    "train_loss_history = []\n",
    "train_acc_shape_history = []\n",
    "train_acc_text_history = []\n",
    "val_acc_shape_history = []\n",
    "val_acc_text_history = []\n",
    "val_loss_history = []\n",
    "num_epochs = 5\n",
    "iter_per_epoch = len(train_loader)\n",
    "log_nth = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = []\n",
    "    total = 0\n",
    "    corrText = 0\n",
    "    corrShape = 0\n",
    "    for i, (path, anchor_shape, pos_text, neg_text_list,neg_shape_list) in enumerate(train_loader):\n",
    "      pos_text = pos_text.to(device)\n",
    "      for idx in range(5):\n",
    "        positive_out = text_model(pos_text[:,1:])\n",
    "        anchor_out = shape_model(anchor_shape)\n",
    "        neg_text = neg_text_list[idx].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        neg_shape_out = shape_model(neg_shape_list[idx])\n",
    "        negative_out = text_model(neg_text[:,1:])\n",
    "        loss = criterion(anchor_out, positive_out, negative_out, neg_shape_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "      \n",
    "      if (i+1) % log_nth == 0:\n",
    "          \n",
    "          print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                  .format(epoch+1, num_epochs, i+1, iter_per_epoch, loss.item()))\n",
    "          \n",
    "      if  (i+1)%500 == 0 : \n",
    "          print(\"pos_out:\",positive_out[0,:10],\"neg_out:\",negative_out[0,:10],\"anchor_out:\",anchor_out[0,:10])\n",
    "          correctText,predictedText,difference = calculateNearest(anchor_out, positive_out)\n",
    "          correctShape,predictedShape,difference = calculateNearest(positive_out, anchor_out)\n",
    "          total = len(correctShape)\n",
    "          corrText = np.sum(np.array(correctText) == np.array(predictedText))\n",
    "          corrShape = np.sum(np.array(correctShape) == np.array(predictedShape))\n",
    "          shapeAcc = 100 * (corrShape / total)\n",
    "          textAcc = 100 * (corrText / total)\n",
    "          print('Train: Text to Shape Retrieval accuracy: {} %'.format(shapeAcc) )\n",
    "          print('Train: Shape to Text Retrieval accuracy: {} %'.format(textAcc) )\n",
    "          train_acc_shape_history.append(shapeAcc)\n",
    "          train_acc_text_history.append(textAcc)\n",
    "      # Validate the model\n",
    "      if  (i+1)%iter_per_epoch == 0:\n",
    "        shape_model.eval()\n",
    "        text_model.eval()\n",
    "        torch.save(shape_model.state_dict(), \"shape_model_triplet.checkpoint\")\n",
    "        torch.save(text_model.state_dict(), \"text_model_triplet.checkpoint\")\n",
    "        with torch.no_grad():\n",
    "          corrText = 0\n",
    "          corrShape = 0\n",
    "          total = 0\n",
    "          for (path, shape, text) in val_loader:\n",
    "              text = text.to(device)\n",
    "              text_embed = text_model(text)\n",
    "              shape_embed = shape_model(shape)\n",
    "              correctText,predictedText,difference = calculateNearest(shape_embed, text_embed)\n",
    "              correctShape,predictedShape,difference = calculateNearest(text_embed, shape_embed)\n",
    "              total += len(correctShape)\n",
    "              corrText += np.sum(np.array(correctText) == np.array(predictedText))\n",
    "              corrShape += np.sum(np.array(correctShape) == np.array(predictedShape))\n",
    "\n",
    "          shapeAcc = 100 * (corrShape / total)\n",
    "          textAcc = 100 * (corrText / total)\n",
    "          print('Validate: Text to Shape Retrieval accuracy: {} %'.format(shapeAcc) )\n",
    "          print('Validate: Shape to Text Retrieval accuracy: {} %'.format(textAcc) )\n",
    "          val_acc_shape_history.append(shapeAcc)\n",
    "          val_acc_text_history.append(textAcc)\n",
    "        shape_model.train()\n",
    "        text_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xryKtCRQWbFL"
   },
   "outputs": [],
   "source": [
    "def calculateAllNearest(firstEmbed, secEmbed, path):\n",
    "  rr_1 = []\n",
    "  rr_5 = []\n",
    "  rr_10 = []\n",
    "  firstEmbed_norm = firstEmbed.norm(p=2,dim=1)\n",
    "  secEmbed_norm = secEmbed.norm(p=2,dim=1)\n",
    "  for i in range(len(firstEmbed)):\n",
    "      distance = (secEmbed-firstEmbed[i]).pow(2).sum(1)\n",
    "      val_10, idx_10 = torch.topk(distance, 10, largest = False)\n",
    "      rr_1.append(path[i]) if idx_10[0] == i else rr_1.append(\"\")\n",
    "      rr_5.append(path[i]) if i in idx_10[:5] else rr_5.append(\"\")\n",
    "      rr_10.append(path[i]) if i in idx_10 else rr_10.append(\"\")\n",
    "  print(\"func:\",len(rr_1),len(rr_5),len(rr_10))\n",
    "  return rr_1,rr_5,rr_10\n",
    "\n",
    "  \n",
    "def write_file(filepath,rr1_Text,rr5_Text,rr10_Text,rr1_Shape,rr5_Shape,rr10_Shape):\n",
    "  print(\"file written\")\n",
    "  with open(filepath, 'w') as file:\n",
    "    file.write(\"RR@1 Text Accuracy:\\n\")\n",
    "    for s in rr1_Text:\n",
    "      if s != \"\":\n",
    "        file.write(s)\n",
    "        file.write(\"\\n\")\n",
    "    file.write(\"RR@5 Text Accuracy:\\n\")\n",
    "    for s in rr5_Text:\n",
    "      if s != \"\":\n",
    "        file.write(s) \n",
    "        file.write(\"\\n\")\n",
    "    file.write(\"RR@10 Text Accuracy:\\n\")\n",
    "    for s in rr10_Text:\n",
    "      if s != \"\":\n",
    "        file.write(s)\n",
    "        file.write(\"\\n\")\n",
    "    file.write(\"RR@1 Shape Accuracy:\\n\")\n",
    "    for s in rr1_Shape:\n",
    "      if s != \"\":\n",
    "        file.write(s)\n",
    "        file.write(\"\\n\")\n",
    "    file.write(\"RR@5 Shape Accuracy:\\n\")\n",
    "    for s in rr5_Shape:\n",
    "      if s != \"\":\n",
    "        file.write(s)\n",
    "        file.write(\"\\n\")\n",
    "    file.write(\"RR@10 Shape Accuracy:\\n\")\n",
    "    for s in rr10_Shape:\n",
    "      if s != \"\":\n",
    "        file.write(s) \n",
    "        file.write(\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2eXghGCXkvFS",
    "outputId": "d3b1537b-31fd-4d9a-dfe2-8370853217b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72759\n",
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3638\n",
      "func: 3638 3638 3638\n",
      "func: 3638 3638 3638\n",
      "file written\n",
      "rr1ShapeAcc: 0.35733919736118747 rr5ShapeAcc: 1.6767454645409565 rr10ShapeAcc: 2.9686641011544803\n",
      "rr1TextAcc: 0.4123144584936778 rr5TextAcc: 1.456844420010995 rr10TextAcc: 2.3639362286970864\n"
     ]
    }
   ],
   "source": [
    "from PointNet2 import Net\n",
    "from embedding import Encoder\n",
    "from embedding import ShapeDecoder\n",
    "from TextDecoder import Decoder\n",
    "import random\n",
    "train_split =  int(0.9 * len(modelIdList))\n",
    "val_split = int(0.95 * len(modelIdList))\n",
    "\n",
    "#val_ds = ShapeText(encoder_input_sentences[train_split:val_split,:], modelIdList[train_split:val_split],\n",
    "#                     categoryList[train_split:val_split], train = False, transform=default_transforms())\n",
    "test_ds = ShapeText(encoder_input_sentences[val_split: ,:], modelIdList[val_split: ], categoryList[val_split: ],\n",
    "                    train = False, transform=default_transforms())\n",
    "#val_loader = DataLoader(dataset=val_ds, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "HIDDEN_SIZE = 300\n",
    "shape_model = Net(300).to(device)\n",
    "text_model = Encoder(embedding_matrix, HIDDEN_SIZE, n_layers=2).to(device)\n",
    "shape_decoder = ShapeDecoder(300).to(device)\n",
    "text_decoder = Decoder(embedding_matrix.astype(np.float32), embedding_matrix.shape[0], 300).to(device)\n",
    "shape_model.load_state_dict(torch.load(\"shape_model_triplet.checkpoint\"))\n",
    "text_model.load_state_dict(torch.load(\"text_model_triplet.checkpoint\"))\n",
    "shape_embed_list = torch.zeros(0, 0).to(device)\n",
    "text_embed_list = torch.zeros(0, 0).to(device)\n",
    "path_list=[]\n",
    "print(len(modelIdList))\n",
    "with torch.no_grad():\n",
    "    corrText = 0\n",
    "    corrShape = 0\n",
    "    total = 0\n",
    "    for path,shape, text in test_loader:\n",
    "      text = text.to(device)\n",
    "      text_embed = text_model(text)\n",
    "      shape_embed = shape_model(shape)\n",
    "      text_embed_list = torch.cat((text_embed_list,text_embed),dim=0) if len(text_embed_list)!=0 else text_embed\n",
    "      shape_embed_list = torch.cat((shape_embed_list,shape_embed),dim=0) if len(shape_embed_list)!=0 else shape_embed\n",
    "      path_list.extend(list(path))\n",
    "      print(len(path_list))\n",
    "    rr1_Text,rr5_Text,rr10_Text = calculateAllNearest(shape_embed_list, text_embed_list, path_list)\n",
    "    rr1_Shape,rr5_Shape,rr10_Shape = calculateAllNearest(text_embed_list, shape_embed_list, path_list)\n",
    "    rr1TextAcc,rr5TextAcc, rr10TextAcc = np.sum(np.array(rr1_Text)!=\"\"),np.sum(np.array(rr5_Text)!=\"\"),np.sum(np.array(rr10_Text)!=\"\")\n",
    "    rr1ShapeAcc,rr5ShapeAcc, rr10ShapeAcc = np.sum(np.array(rr1_Shape)!=\"\"),np.sum(np.array(rr5_Shape)!=\"\"),np.sum(np.array(rr10_Shape)!=\"\")\n",
    "    total = 100/len(rr1_Shape)\n",
    "    write_file(\"triplet_loss_results\",rr1_Text,rr5_Text,rr10_Text,rr1_Shape,rr5_Shape,rr10_Shape)\n",
    "    print(\"rr1ShapeAcc:\", rr1ShapeAcc*total, \"rr5ShapeAcc:\", rr5ShapeAcc*total, \"rr10ShapeAcc:\", rr10ShapeAcc*total)\n",
    "    print(\"rr1TextAcc:\", rr1TextAcc*total, \"rr5TextAcc:\", rr5TextAcc*total, \"rr10TextAcc:\", rr10TextAcc*total)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "pk_3505dWtXk",
    "outputId": "b7741dc6-e40b-4954-8e90-7d8e617c5459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6127, -1.0223],\n",
      "         [ 1.6285, -1.9668],\n",
      "         [-0.9557, -0.4103]],\n",
      "\n",
      "        [[-1.4859, -0.5730],\n",
      "         [ 0.0153, -0.3187],\n",
      "         [-1.6082,  1.0959]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(2,3,2)\n",
    "print(x)\n",
    "val,idx =torch.max(x,dim=1)\n",
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20j7RFGCBGBv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CrossModal_Triplet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
